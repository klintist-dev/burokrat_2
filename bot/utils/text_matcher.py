# bot/utils/text_matcher.py
import re
from difflib import SequenceMatcher
from typing import List, Dict, Optional


class TextMatcher:
    """–ö–ª–∞—Å—Å –¥–ª—è —É–º–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞"""

    @staticmethod
    def normalize(text: str) -> str:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        """
        if not text:
            return ""

        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        text = text.lower()

        # –ó–∞–º–µ–Ω—è–µ–º —ë –Ω–∞ –µ
        text = text.replace('—ë', '–µ')

        # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
        text = re.sub(r'["\'¬´¬ª‚Äû‚Äú*.,!?;:()\[\]{}]', '', text)

        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        text = ' '.join(text.split())

        return text.strip()

    @staticmethod
    def calculate_relevance(query: str, name: str) -> float:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å—É
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å–ª–æ –æ—Ç 0 –¥–æ 1
        """
        norm_query = TextMatcher.normalize(query)
        norm_name = TextMatcher.normalize(name)

        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
        query_words = set(norm_query.split())
        name_words = set(norm_name.split())

        if not query_words:
            return 0.0

        # –°—á–∏—Ç–∞–µ–º, —Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –µ—Å—Ç—å –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
        matched_words = query_words.intersection(name_words)

        # –í–µ—Å–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        score = 0.0

        # 1. –ì–ª–∞–≤–Ω–æ–µ: –ø—Ä–æ—Ü–µ–Ω—Ç —Å–æ–≤–ø–∞–≤—à–∏—Ö —Å–ª–æ–≤ (0-1)
        word_match_ratio = len(matched_words) / len(query_words)
        score += word_match_ratio * 0.7  # 70% –≤–µ—Å–∞

        # 2. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ñ—Ä–∞–∑—ã
        if norm_query in norm_name:
            score += 0.2  # +20% –µ—Å–ª–∏ —Ñ—Ä–∞–∑–∞ —Ü–µ–ª–∏–∫–æ–º –µ—Å—Ç—å –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏

        # 3. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–¥—É—Ç –ª–∏ —Å–ª–æ–≤–∞ –≤ —Ç–æ–º –∂–µ –ø–æ—Ä—è–¥–∫–µ
        query_list = norm_query.split()
        name_list = norm_name.split()

        # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–ª–æ–≤ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
        matches = 0
        for i in range(len(name_list) - len(query_list) + 1):
            if name_list[i:i + len(query_list)] == query_list:
                matches += 1

        if matches > 0:
            score += 0.1  # +10% –∑–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ—Ä—è–¥–∫–∞

        return min(score, 1.0)  # –ù–µ –±–æ–ª—å—à–µ 1

    @staticmethod
    def rank_candidates(query: str, candidates: List[Dict], threshold: float = 0.1) -> List[Dict]:
        """
        –†–∞–Ω–∂–∏—Ä—É–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        """
        print(f"\nüîç –†–ê–ù–ñ–ò–†–û–í–ê–ù–ò–ï –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{query}'")

        norm_query = TextMatcher.normalize(query)
        print(f"   –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: '{norm_query}'")

        ranked = []

        for candidate in candidates:
            name = candidate.get('name', '')

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
            relevance = TextMatcher.calculate_relevance(query, name)

            # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏
            norm_name = TextMatcher.normalize(name)
            query_words = set(norm_query.split())
            name_words = set(norm_name.split())
            matched_words = query_words.intersection(name_words)

            print(f"\n   –ö–∞–Ω–¥–∏–¥–∞—Ç {candidate.get('inn')}:")
            print(f"      —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {relevance:.3f}")
            print(f"      —Å–æ–≤–ø–∞–ª–æ —Å–ª–æ–≤: {len(matched_words)}/{len(query_words)}")
            print(f"      —Å–ª–æ–≤–∞: {sorted(matched_words)}")

            if relevance >= threshold:
                candidate_copy = candidate.copy()
                candidate_copy['relevance'] = relevance
                candidate_copy['similarity'] = int(relevance * 100)  # –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                candidate_copy['matched_words'] = list(matched_words)
                ranked.append(candidate_copy)

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        ranked.sort(key=lambda x: x['relevance'], reverse=True)

        print(f"\nüèÜ –¢–û–ü –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:")
        for i, org in enumerate(ranked[:5], 1):
            print(f"   {i}. {org['relevance']:.1%} - {org['inn']}")

        return ranked